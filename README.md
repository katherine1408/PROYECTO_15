# ğŸ¥ Sprint 15 â€“ ClasificaciÃ³n AutomÃ¡tica de ReseÃ±as Negativas (Film Junky Union)

## ğŸ“Œ DescripciÃ³n del Proyecto

**Film Junky Union**, una comunidad para amantes del cine clÃ¡sico, estÃ¡ desarrollando un sistema automÃ¡tico para **detectar crÃ­ticas negativas** en reseÃ±as de pelÃ­culas. 

El objetivo de este proyecto es construir y comparar modelos de **aprendizaje automÃ¡tico** que clasifiquen reseÃ±as como **positivas o negativas**, usando datos reales de IMDB. Para considerarse exitoso, el modelo debe alcanzar una mÃ©trica **F1 â‰¥ 0.85** en el conjunto de prueba.

## ğŸ¯ Objetivos del Proyecto

- Explorar los datos y verificar el equilibrio de clases.
- Preprocesar las reseÃ±as de texto.
- Vectorizar las reseÃ±as para entrenar modelos.
- Comparar al menos tres modelos de clasificaciÃ³n:
  - `LogisticRegression`
  - `RandomForestClassifier` o `GradientBoosting`
  - (opcional) `BERT` aplicado a subconjuntos
- Evaluar los modelos con mÃ©tricas (`F1`, `accuracy`, `confusion matrix`)
- Clasificar reseÃ±as nuevas manuales con los modelos entrenados.

## ğŸ“ Dataset utilizado

- `imdb_reviews.tsv`

Columnas:

- `review`: texto de la reseÃ±a
- `pos`: etiqueta de sentimiento (1 = positiva, 0 = negativa)
- `ds_part`: conjunto de pertenencia (`train` o `test`)

## ğŸ§° Funcionalidades del Proyecto

### ğŸ” AnÃ¡lisis Exploratorio

- CÃ¡lculo de proporciones de clases
- VisualizaciÃ³n de distribuciÃ³n de longitud de reseÃ±as

### ğŸ§¹ Preprocesamiento y vectorizaciÃ³n

- Limpieza bÃ¡sica del texto: minÃºsculas, signos, stopwords
- TokenizaciÃ³n y vectorizaciÃ³n con:
  - `CountVectorizer`
  - `TfidfVectorizer`

### ğŸ¤– Modelado

- Entrenamiento con mÃºltiples algoritmos de clasificaciÃ³n
- Ajuste bÃ¡sico de hiperparÃ¡metros
- EvaluaciÃ³n con funciÃ³n `evaluate_model()`

### âœ¨ ClasificaciÃ³n personalizada

- PredicciÃ³n de reseÃ±as escritas manualmente
- ComparaciÃ³n de decisiones entre modelos

### (Opcional) ğŸ§  BERT
- VectorizaciÃ³n con `BERT_text_to_embeddings()` para un subconjunto reducido
- EvaluaciÃ³n del impacto en rendimiento

## ğŸ“Š Herramientas utilizadas

- Python  
- pandas / numpy  
- scikit-learn  
- matplotlib / seaborn  
- nltk / re  
- (opcional) `transformers` de Hugging Face para BERT

---

ğŸ“Œ Proyecto desarrollado como parte del Sprint 15 del programa de Ciencia de Datos en **TripleTen**.
